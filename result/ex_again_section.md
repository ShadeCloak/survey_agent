\subsection{Program Generation and Execution for Enhanced Reasoning}
%IDs:['5', '6', '11', '12', '15', '16', '18']
%In the field of artificial intelligence, one area that has seen significant developments is the integration of language models with code execution and reasoning. This synergy has led to sophisticated systems that can not only understand and generate code but also reason through complex problems via pseudocode and symbolic formulas. Here, we delve into several methodologies that have been employed in this domain, highlighting their unique characteristics and their contributions to enhancing the capabilities of language models in programming tasks.

Chain of Code (CoC) is a novel approach that has been introduced to improve the reasoning abilities of language models (LLMs) by leveraging code execution and emulation. The key innovation in CoC is the ability of LLMs to format semantic sub-tasks into flexible pseudocode that can be captured by an interpreter, which then hands off undefined behaviors to an LLM-based code emulator for simulation. This capability broadens the scope of problems that LLMs can address, especially those that require a mix of logic, arithmetic, and semantic reasoning. The effectiveness of CoC is evident from its performance on various benchmark tests, where it consistently outshines other baselines, demonstrating improved accuracy and expanded reasoning capabilities~\citep{coch2023}.

Another significant contribution comes from the Think-and-Execute framework, which breaks down the reasoning process into two distinct steps: Think and Execute. In the Think phase, an LLM discovers a task-level logic shared across all instances of a given task and expresses it in pseudocode. The Execute phase involves tailoring the pseudocode to individual instances and simulating its execution. This framework effectively guides LLMs towards discovering task-level logic that can be reused across different instances, enhancing their reasoning abilities without the need for instance-specific codes. The experiments conducted on seven algorithmic reasoning tasks underscore the superiority of this method over traditional instance-specific reasoning approaches, showcasing the potential of pseudocode to better steer the reasoning of LLMs~\citep{te2024}.

ReGAL, or Refactoring for Generalizable Abstraction Learning, is another innovative framework that addresses the limitations of LLMs in generating reusable code. By refactoring existing programs without altering their execution output, ReGAL identifies and learns generalizable abstractions that can be utilized across diverse domains. This method improves the accuracy of LLMs in predicting programs, as illustrated by their performance on various datasets, including LOGO, Date reasoning, TextCraft, and MATH. Notably, ReGAL-augmented LLMs outperform the baseline models across multiple domains, underscoring the efficacy of learning reusable functions through refactoring~\citep{regal2024}.

In sum, these methodologies—CoC, Think-and-Execute, and ReGAL—represent significant strides in enhancing the coding and reasoning abilities of LLMs. Through innovative approaches to code generation, execution, and refactoring, these frameworks pave the way for more efficient, accurate, and generalizable problem-solving in the realm of programming and algorithmic reasoning. As research in this area continues to evolve, we can foresee even greater advancements in the capabilities of LLMs to tackle complex programming tasks.